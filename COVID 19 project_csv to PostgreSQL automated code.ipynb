{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c64044d",
   "metadata": {},
   "source": [
    "# Importing a CSV file into a PostgrSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b1cb2",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- download the CSV file from the web using Python\n",
    "- import a csv file into a pd dataframe \n",
    "- clean the table name and remove all the all extra symbols, spaces, capital letters\n",
    "- clean the column headers and remove all the all extra symbols, spaces, capital letters\n",
    "- write the create table SQL statement\n",
    "- import the data into the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551f3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed984a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\manuk\\\\OneDrive\\\\Desktop\\\\MasterSchool_final\\\\Portfolio_projects\\\\COVID_19'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory\n",
    "os.chdir(r'C:\\Users\\manuk\\OneDrive\\Desktop\\MasterSchool_final\\Portfolio_projects\\COVID_19')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335f20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the requests library, which allows us to make HTTP requests\n",
    "import requests\n",
    "\n",
    "# set the URL of the CSV file we want to download\n",
    "url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "\n",
    "# make a GET request to the URL, and store the response in a variable named 'response'\n",
    "response = requests.get(url)\n",
    "\n",
    "# open a file named 'owid-covid-data.csv' in binary write mode ('wb'), and store it in a variable named 'f'\n",
    "with open(\"owid-covid-data.csv\", \"wb\") as f:\n",
    "    # write the content of the response to the file\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70851ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>population</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-01-03          NaN        0.0   \n",
       "1      AFG      Asia  Afghanistan  2020-01-04          NaN        0.0   \n",
       "2      AFG      Asia  Afghanistan  2020-01-05          NaN        0.0   \n",
       "3      AFG      Asia  Afghanistan  2020-01-06          NaN        0.0   \n",
       "4      AFG      Asia  Afghanistan  2020-01-07          NaN        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         0.0                  NaN  ...   \n",
       "1                 NaN           NaN         0.0                  NaN  ...   \n",
       "2                 NaN           NaN         0.0                  NaN  ...   \n",
       "3                 NaN           NaN         0.0                  NaN  ...   \n",
       "4                 NaN           NaN         0.0                  NaN  ...   \n",
       "\n",
       "   male_smokers  handwashing_facilities  hospital_beds_per_thousand  \\\n",
       "0           NaN                  37.746                         0.5   \n",
       "1           NaN                  37.746                         0.5   \n",
       "2           NaN                  37.746                         0.5   \n",
       "3           NaN                  37.746                         0.5   \n",
       "4           NaN                  37.746                         0.5   \n",
       "\n",
       "   life_expectancy  human_development_index  population  \\\n",
       "0            64.83                    0.511  41128772.0   \n",
       "1            64.83                    0.511  41128772.0   \n",
       "2            64.83                    0.511  41128772.0   \n",
       "3            64.83                    0.511  41128772.0   \n",
       "4            64.83                    0.511  41128772.0   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame from a CSV file named 'data.csv'\n",
    "df = pd.read_csv(\"owid-covid-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a145b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_code\n",
      "continent\n",
      "location\n",
      "date\n",
      "total_cases\n",
      "new_cases\n",
      "new_cases_smoothed\n",
      "total_deaths\n",
      "new_deaths\n",
      "new_deaths_smoothed\n",
      "total_cases_per_million\n",
      "new_cases_per_million\n",
      "new_cases_smoothed_per_million\n",
      "total_deaths_per_million\n",
      "new_deaths_per_million\n",
      "new_deaths_smoothed_per_million\n",
      "reproduction_rate\n",
      "icu_patients\n",
      "icu_patients_per_million\n",
      "hosp_patients\n",
      "hosp_patients_per_million\n",
      "weekly_icu_admissions\n",
      "weekly_icu_admissions_per_million\n",
      "weekly_hosp_admissions\n",
      "weekly_hosp_admissions_per_million\n",
      "total_tests\n",
      "new_tests\n",
      "total_tests_per_thousand\n",
      "new_tests_per_thousand\n",
      "new_tests_smoothed\n",
      "new_tests_smoothed_per_thousand\n",
      "positive_rate\n",
      "tests_per_case\n",
      "tests_units\n",
      "total_vaccinations\n",
      "people_vaccinated\n",
      "people_fully_vaccinated\n",
      "total_boosters\n",
      "new_vaccinations\n",
      "new_vaccinations_smoothed\n",
      "total_vaccinations_per_hundred\n",
      "people_vaccinated_per_hundred\n",
      "people_fully_vaccinated_per_hundred\n",
      "total_boosters_per_hundred\n",
      "new_vaccinations_smoothed_per_million\n",
      "new_people_vaccinated_smoothed\n",
      "new_people_vaccinated_smoothed_per_hundred\n",
      "stringency_index\n",
      "population_density\n",
      "median_age\n",
      "aged_65_older\n",
      "aged_70_older\n",
      "gdp_per_capita\n",
      "extreme_poverty\n",
      "cardiovasc_death_rate\n",
      "diabetes_prevalence\n",
      "female_smokers\n",
      "male_smokers\n",
      "handwashing_facilities\n",
      "hospital_beds_per_thousand\n",
      "life_expectancy\n",
      "human_development_index\n",
      "population\n",
      "excess_mortality_cumulative_absolute\n",
      "excess_mortality_cumulative\n",
      "excess_mortality\n",
      "excess_mortality_cumulative_per_million\n"
     ]
    }
   ],
   "source": [
    "# loop over the columns of the DataFrame 'df'\n",
    "for i in df.columns:\n",
    "    # print the name of each column\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ecee42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the covid_deaths dataframe with columns until weekly_hosp_admissions_per_million\n",
    "covid_deaths = df.loc[:, :'weekly_hosp_admissions_per_million']\n",
    "covid_deaths.insert(3, 'population', df['population'])  # add the 'population' column after 'date'\n",
    "\n",
    "# create the covid_vaccinations dataframe with columns from total_tests to the end\n",
    "covid_vaccinations = df.loc[:, 'total_tests':]\n",
    "covid_vaccinations = covid_vaccinations.drop('population', axis=1)  # remove the 'population' column from the second dataframe\n",
    "\n",
    "# add the first 4 columns from df to covid_vaccinations\n",
    "covid_vaccinations = pd.concat([df.iloc[:, :4], covid_vaccinations], axis=1)\n",
    "\n",
    "# save the dataframes to CSV files\n",
    "covid_deaths.to_csv('covid_deaths.csv', index=False)\n",
    "covid_vaccinations.to_csv('covid_vaccinations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2adebaf",
   "metadata": {},
   "source": [
    "## Find CSV files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556c9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find CSV files in my currecnt working directory\n",
    "# isolate only CSV files\n",
    "\n",
    "csv_files=[]\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508f3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new directory\n",
    "\n",
    "dataset_dir = 'datasets'\n",
    "\n",
    "# create the bash command to make a new directory\n",
    "#  mkdir dataset_dir\n",
    "\n",
    "try:\n",
    "    mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "    os.system(mkdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394e50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the full path of the file in the main folder\n",
    "data_path = os.getcwd() + '\\\\' + dataset_dir + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755c92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all files in the main folder\n",
    "for file_name in os.listdir(os.getcwd()):\n",
    "    # check if the file is a CSV file\n",
    "    if file_name.endswith('.csv'):\n",
    "        # construct the full path of the file in the main folder\n",
    "        file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "        # construct the full path of the file in the datasets subfolder\n",
    "        new_file_path = os.path.join(data_path, file_name)\n",
    "\n",
    "        # use the shutil module's move() function to move the file\n",
    "        shutil.copy(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15165b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_deaths.csv\n",
      "covid_vaccinations.csv\n",
      "owid-covid-data.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = os.getcwd() + '/' + dataset_dir + '/'\n",
    "\n",
    "df = {}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df[file] = pd.read_csv(data_path+file)\n",
    "    except UnicodeDecodeError:\n",
    "        df[file] = pd.read_csv(data_path+file, encoding=\"ISO-8859-1\")\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd609d",
   "metadata": {},
   "source": [
    "## Clean table names and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b54145",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened database successfully\n",
      "covid_deaths was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table covid_deaths imported to db completed\n",
      "opened database successfully\n",
      "covid_vaccinations was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table covid_vaccinations imported to db completed\n",
      "opened database successfully\n",
      "owid_covid_data was created successfully\n",
      "file opened in memory\n",
      "file copied to db\n",
      "table owid_covid_data imported to db completed\n",
      "all tables have been successfully imported into the db\n"
     ]
    }
   ],
   "source": [
    "for k in csv_files:\n",
    "    dataframe = df[k]\n",
    "    \n",
    "    clean_tbl_name = k.lower().replace(\" \", \"_\").replace(\"-\",\"_\")\\\n",
    "                    .replace(r\"/\",\"_\").replace(\"\\\\\",\"_\")\\\n",
    "                    .replace(\"$\",\"\").replace(\"%\",\"\")\n",
    "    \n",
    "    #remove .csv extension from clean_tbl_name\n",
    "    tbl_name = '{0}'.format(clean_tbl_name.split('.')[0])\n",
    "    \n",
    "    dataframe.columns = [x.lower().replace(\" \", \"_\").replace(\"-\",\"_\")\\\n",
    "                    .replace(r\"/\",\"_\").replace(\"\\\\\",\"_\")\\\n",
    "                    .replace(\"$\",\"\").replace(\"%\",\"\") for x in dataframe.columns]   \n",
    "    \n",
    "    #replacment dictionary that maps pandas dtypes to sql dtypes\n",
    "    replacements = {\n",
    "    'object':'varchar',\n",
    "    'float64':'float',\n",
    "    'int64':'int',\n",
    "    'datetime64':'timestamp', \n",
    "    'timedelta64[ns]':'varchar'\n",
    "}    \n",
    "    \n",
    "    # table schema\n",
    "    \n",
    "    # create a list of formatted column names and data types\n",
    "    columns = [\"{} {}\".format(n, d) for (n, d) in zip(dataframe.columns, dataframe.dtypes.replace(replacements))]\n",
    "\n",
    "    # join the list into a comma-separated string\n",
    "    col_str = \", \".join(columns)\n",
    "    \n",
    "    # open a database connection\n",
    "    host='localhost'\n",
    "    dbname='PortfolioProjects'\n",
    "    user='postgres'\n",
    "    password='elmanlus84'\n",
    "\n",
    "\n",
    "    conn_string = \"host=%s dbname=%s user=%s password=%s\" % (host, dbname, user, password)\n",
    "\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    print('opened database successfully')\n",
    "    \n",
    "    # drop tables with same name\n",
    "    cursor.execute('drop table if exists %s;' % (tbl_name))    \n",
    "    # creat table\n",
    "    cursor.execute('create table %s (%s)' % (tbl_name,col_str))\n",
    "    print('{0} was created successfully'.format(tbl_name))\n",
    "    \n",
    "    # insert values to table\n",
    "\n",
    "    # save the df to csv\n",
    "    dataframe.to_csv(k, header=dataframe.columns, index=False, encoding='utf-8')\n",
    "\n",
    "    # open the csv file, save it as an object\n",
    "    my_file = open(k)\n",
    "    print('file opened in memory')\n",
    "    \n",
    "    \n",
    "    # upload to db\n",
    "    SQL_statement = \"\"\"\n",
    "\n",
    "    COPY %s FROM STDIN WITH\n",
    "    CSV\n",
    "    HEADER\n",
    "    DELIMITER AS ','\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.copy_expert(sql=SQL_statement % tbl_name, file=my_file)\n",
    "    print('file copied to db')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print('table {0} imported to db completed'.format(tbl_name))\n",
    "    \n",
    "#for loop end message\n",
    "print('all tables have been successfully imported into the db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
